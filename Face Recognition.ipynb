{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Topics in Information Systems\n",
    "### Lab 2\n",
    "\n",
    "\n",
    "# Face Recognition\n",
    "\n",
    "\n",
    "#### by: Youssef Sherif ID: 72, and Ramez Maher ID: 27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement:\n",
    "\n",
    "It is required to perform facial recognition -tell the subject's id given an image of him/her- on a database of 40 subjects. Each subject has 10 images in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics \n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean(data):\n",
    "    means = []\n",
    "    trans_data = np.transpose(data)\n",
    "    for i in range(len(trans_data)):\n",
    "        means.append(np.mean(trans_data[i]))\n",
    "    return np.array(means)\n",
    "\n",
    "def center_data(data, means):\n",
    "    transpose_means = np.transpose(means)\n",
    "    Z = []\n",
    "    for i in range(len(data)):\n",
    "        Z.append(data[i] - transpose_means)\n",
    "    return np.array(Z)\n",
    "\n",
    "def compute_cov_matrix(Z):\n",
    "    n = len(Z)\n",
    "    Z_trans = np.transpose(Z)\n",
    "    sigma = np.matmul(Z_trans, Z)/n\n",
    "    return sigma\n",
    "\n",
    "def choose_eigenvectors(eigenvalues, alpha):\n",
    "    total_variance = np.sum(eigenvalues)\n",
    "    variance_captured = 0\n",
    "    fraction = 0\n",
    "    index = len(eigenvalues)-1\n",
    "    while fraction < alpha:\n",
    "        variance_captured+= eigenvalues[index]\n",
    "        index-= 1\n",
    "        fraction = variance_captured/total_variance\n",
    "    return index                                \n",
    "\n",
    "def reduce_basis(eigenvectors, index):\n",
    "    i = len(eigenvectors)-1\n",
    "    u = []\n",
    "    while i > index:\n",
    "        u.append(eigenvectors[i])\n",
    "        i-= 1\n",
    "    return np.array(u)\n",
    "\n",
    "def get_reduced_eigenvectors(data, alpha):\n",
    "    means = compute_mean(data)\n",
    "    Z = center_data(data, means)\n",
    "    cov_matrix = compute_cov_matrix(Z)\n",
    "    eigenVals, eigenVects = np.linalg.eigh(cov_matrix)\n",
    "    index = choose_eigenvectors(eigenVals, alpha)\n",
    "    Ur = reduce_basis(eigenVects, index)\n",
    "    return Ur\n",
    "    \n",
    "def pca(Ur, data):\n",
    "    Ur_trans = np.transpose(Ur)\n",
    "    A = np.matmul(data, Ur_trans)\n",
    "    return A\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating data matrix and labels vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = \"data\"\n",
    "\n",
    "features_vec = []\n",
    "labels = []\n",
    "for i in range(1, 41):\n",
    "    path = os.path.join(DATAPATH, \"s\"+str(i))\n",
    "    for img in os.listdir(path):\n",
    "        image = imread(os.path.join(path, img), as_gray=True)\n",
    "        features_vec.append(image.flatten())\n",
    "        labels.append(i)\n",
    "\n",
    "data_matrix = np.array(features_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spliting dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train = []\n",
    "x1_test = []\n",
    "y1_train = []\n",
    "y1_test = []\n",
    "\n",
    "#Primary train and test sets split 50/50\n",
    "for i in range(0, 400):\n",
    "    if i%2 == 1:\n",
    "        x1_train.append(data_matrix[i])\n",
    "        y1_train.append(labels[i])\n",
    "    else:\n",
    "        x1_test.append(data_matrix[i])\n",
    "        y1_test.append(labels[i])\n",
    "x1_train = np.array(x1_train)\n",
    "x1_test = np.array(x1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction using PCA and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for alpha = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ur1 = get_reduced_eigenvectors(x1_train, 0.8)\n",
    "A1_train = pca(Ur1, x1_train)\n",
    "A1_test = pca(Ur1, x1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "classifier.fit(A1_train, y1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.40      0.57         5\n",
      "           2       0.80      0.80      0.80         5\n",
      "           3       0.75      0.60      0.67         5\n",
      "           4       0.83      1.00      0.91         5\n",
      "           5       0.56      1.00      0.71         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       0.83      1.00      0.91         5\n",
      "           8       1.00      1.00      1.00         5\n",
      "           9       0.71      1.00      0.83         5\n",
      "          10       1.00      1.00      1.00         5\n",
      "          11       1.00      0.80      0.89         5\n",
      "          12       1.00      0.80      0.89         5\n",
      "          13       0.80      0.80      0.80         5\n",
      "          14       0.83      1.00      0.91         5\n",
      "          15       1.00      1.00      1.00         5\n",
      "          16       1.00      0.60      0.75         5\n",
      "          17       0.83      1.00      0.91         5\n",
      "          18       0.80      0.80      0.80         5\n",
      "          19       1.00      1.00      1.00         5\n",
      "          20       1.00      0.80      0.89         5\n",
      "          21       1.00      1.00      1.00         5\n",
      "          22       1.00      1.00      1.00         5\n",
      "          23       0.80      0.80      0.80         5\n",
      "          24       0.71      1.00      0.83         5\n",
      "          25       0.50      1.00      0.67         5\n",
      "          26       1.00      1.00      1.00         5\n",
      "          27       1.00      1.00      1.00         5\n",
      "          28       1.00      0.40      0.57         5\n",
      "          29       0.83      1.00      0.91         5\n",
      "          30       1.00      1.00      1.00         5\n",
      "          31       1.00      0.80      0.89         5\n",
      "          32       1.00      1.00      1.00         5\n",
      "          33       1.00      1.00      1.00         5\n",
      "          34       1.00      1.00      1.00         5\n",
      "          35       1.00      0.20      0.33         5\n",
      "          36       0.80      0.80      0.80         5\n",
      "          37       0.71      1.00      0.83         5\n",
      "          38       0.75      0.60      0.67         5\n",
      "          39       0.80      0.80      0.80         5\n",
      "          40       0.67      0.40      0.50         5\n",
      "\n",
      "    accuracy                           0.85       200\n",
      "   macro avg       0.88      0.85      0.85       200\n",
      "weighted avg       0.88      0.85      0.85       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predicted = classifier.predict(A1_test)\n",
    "results = metrics.classification_report(y1_test, y_predicted)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When alpha is 0.8, the accuracy is 0.85 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for alpha = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.60      0.67         5\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       1.00      0.80      0.89         5\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       0.62      1.00      0.77         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       0.83      1.00      0.91         5\n",
      "           8       1.00      1.00      1.00         5\n",
      "           9       0.67      0.80      0.73         5\n",
      "          10       1.00      1.00      1.00         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       1.00      1.00      1.00         5\n",
      "          13       0.83      1.00      0.91         5\n",
      "          14       1.00      1.00      1.00         5\n",
      "          15       1.00      1.00      1.00         5\n",
      "          16       0.80      0.80      0.80         5\n",
      "          17       1.00      1.00      1.00         5\n",
      "          18       1.00      1.00      1.00         5\n",
      "          19       1.00      1.00      1.00         5\n",
      "          20       1.00      0.80      0.89         5\n",
      "          21       0.56      1.00      0.71         5\n",
      "          22       1.00      1.00      1.00         5\n",
      "          23       0.60      0.60      0.60         5\n",
      "          24       1.00      0.80      0.89         5\n",
      "          25       0.50      1.00      0.67         5\n",
      "          26       1.00      1.00      1.00         5\n",
      "          27       1.00      1.00      1.00         5\n",
      "          28       1.00      0.80      0.89         5\n",
      "          29       0.80      0.80      0.80         5\n",
      "          30       0.83      1.00      0.91         5\n",
      "          31       1.00      0.80      0.89         5\n",
      "          32       1.00      0.80      0.89         5\n",
      "          33       0.83      1.00      0.91         5\n",
      "          34       1.00      1.00      1.00         5\n",
      "          35       0.00      0.00      0.00         5\n",
      "          36       1.00      0.80      0.89         5\n",
      "          37       0.83      1.00      0.91         5\n",
      "          38       1.00      0.40      0.57         5\n",
      "          39       1.00      0.80      0.89         5\n",
      "          40       0.75      0.60      0.67         5\n",
      "\n",
      "    accuracy                           0.88       200\n",
      "   macro avg       0.88      0.88      0.87       200\n",
      "weighted avg       0.88      0.88      0.87       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramez\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ramez\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ramez\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Ur1 = get_reduced_eigenvectors(x1_train, 0.85)\n",
    "A1_train = pca(Ur1, x1_train)\n",
    "A1_test = pca(Ur1, x1_test)\n",
    "classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "classifier.fit(A1_train, y1_train)\n",
    "y_predicted = classifier.predict(A1_test)\n",
    "results = metrics.classification_report(y1_test, y_predicted)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for alpha 0.85, the accuracy increased to 0.88."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for alpha = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.60      0.75         5\n",
      "           2       0.83      1.00      0.91         5\n",
      "           3       1.00      0.80      0.89         5\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       0.50      1.00      0.67         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       1.00      1.00      1.00         5\n",
      "           9       0.67      0.80      0.73         5\n",
      "          10       1.00      1.00      1.00         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       1.00      1.00      1.00         5\n",
      "          13       1.00      1.00      1.00         5\n",
      "          14       1.00      1.00      1.00         5\n",
      "          15       0.83      1.00      0.91         5\n",
      "          16       1.00      0.60      0.75         5\n",
      "          17       1.00      1.00      1.00         5\n",
      "          18       0.80      0.80      0.80         5\n",
      "          19       0.83      1.00      0.91         5\n",
      "          20       1.00      1.00      1.00         5\n",
      "          21       0.71      1.00      0.83         5\n",
      "          22       1.00      1.00      1.00         5\n",
      "          23       0.75      0.60      0.67         5\n",
      "          24       1.00      1.00      1.00         5\n",
      "          25       0.56      1.00      0.71         5\n",
      "          26       1.00      1.00      1.00         5\n",
      "          27       1.00      1.00      1.00         5\n",
      "          28       1.00      0.80      0.89         5\n",
      "          29       1.00      1.00      1.00         5\n",
      "          30       1.00      1.00      1.00         5\n",
      "          31       1.00      1.00      1.00         5\n",
      "          32       1.00      0.80      0.89         5\n",
      "          33       1.00      1.00      1.00         5\n",
      "          34       1.00      1.00      1.00         5\n",
      "          35       1.00      0.20      0.33         5\n",
      "          36       1.00      1.00      1.00         5\n",
      "          37       0.83      1.00      0.91         5\n",
      "          38       1.00      0.80      0.89         5\n",
      "          39       1.00      1.00      1.00         5\n",
      "          40       1.00      0.40      0.57         5\n",
      "\n",
      "    accuracy                           0.91       200\n",
      "   macro avg       0.93      0.91      0.90       200\n",
      "weighted avg       0.93      0.91      0.90       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Ur1 = get_reduced_eigenvectors(x1_train, 0.9)\n",
    "A1_train = pca(Ur1, x1_train)\n",
    "A1_test = pca(Ur1, x1_test)\n",
    "classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "classifier.fit(A1_train, y1_train)\n",
    "y_predicted = classifier.predict(A1_test)\n",
    "results = metrics.classification_report(y1_test, y_predicted)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy increased again to 0.91, as we are increasing alpha(accepted fraction of total variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for alpha = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.60      0.75         5\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       0.83      1.00      0.91         5\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       0.56      1.00      0.71         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       1.00      1.00      1.00         5\n",
      "           9       1.00      0.80      0.89         5\n",
      "          10       1.00      1.00      1.00         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       1.00      1.00      1.00         5\n",
      "          13       1.00      1.00      1.00         5\n",
      "          14       1.00      1.00      1.00         5\n",
      "          15       0.83      1.00      0.91         5\n",
      "          16       1.00      0.80      0.89         5\n",
      "          17       1.00      1.00      1.00         5\n",
      "          18       1.00      1.00      1.00         5\n",
      "          19       1.00      1.00      1.00         5\n",
      "          20       1.00      1.00      1.00         5\n",
      "          21       0.83      1.00      0.91         5\n",
      "          22       1.00      1.00      1.00         5\n",
      "          23       0.80      0.80      0.80         5\n",
      "          24       0.83      1.00      0.91         5\n",
      "          25       0.62      1.00      0.77         5\n",
      "          26       1.00      1.00      1.00         5\n",
      "          27       1.00      1.00      1.00         5\n",
      "          28       1.00      0.80      0.89         5\n",
      "          29       1.00      1.00      1.00         5\n",
      "          30       1.00      1.00      1.00         5\n",
      "          31       1.00      1.00      1.00         5\n",
      "          32       1.00      1.00      1.00         5\n",
      "          33       1.00      1.00      1.00         5\n",
      "          34       1.00      1.00      1.00         5\n",
      "          35       1.00      0.20      0.33         5\n",
      "          36       1.00      1.00      1.00         5\n",
      "          37       0.83      1.00      0.91         5\n",
      "          38       1.00      0.80      0.89         5\n",
      "          39       1.00      1.00      1.00         5\n",
      "          40       0.67      0.40      0.50         5\n",
      "\n",
      "    accuracy                           0.93       200\n",
      "   macro avg       0.95      0.93      0.92       200\n",
      "weighted avg       0.95      0.93      0.92       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Ur1 = get_reduced_eigenvectors(x1_train, 0.95)\n",
    "A1_train = pca(Ur1, x1_train)\n",
    "A1_test = pca(Ur1, x1_test)\n",
    "classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "classifier.fit(A1_train, y1_train)\n",
    "y_predicted = classifier.predict(A1_test)\n",
    "results = metrics.classification_report(y1_test, y_predicted)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best accuracy yet 0.93, for alpha = 0.95.\n",
    "Depending on these results we can conclude that, the more the value of accepted fraction of total variance, the better the accuracy will be, but this will also mean more features to consider, which could have negative effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-parameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from this part, and given that using alpha = 0.95 yielded best accuracy, it will be used for all the next tests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ur1 = get_reduced_eigenvectors(x1_train, 0.95)\n",
    "A1_train = pca(Ur1, x1_train)\n",
    "A1_test = pca(Ur1, x1_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for K = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.60      0.75         5\n",
      "           2       0.62      1.00      0.77         5\n",
      "           3       1.00      0.80      0.89         5\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       0.56      1.00      0.71         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       0.83      1.00      0.91         5\n",
      "           8       1.00      1.00      1.00         5\n",
      "           9       0.80      0.80      0.80         5\n",
      "          10       1.00      1.00      1.00         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       1.00      1.00      1.00         5\n",
      "          13       1.00      1.00      1.00         5\n",
      "          14       0.83      1.00      0.91         5\n",
      "          15       0.67      0.40      0.50         5\n",
      "          16       1.00      0.80      0.89         5\n",
      "          17       1.00      1.00      1.00         5\n",
      "          18       1.00      1.00      1.00         5\n",
      "          19       0.83      1.00      0.91         5\n",
      "          20       1.00      0.80      0.89         5\n",
      "          21       0.71      1.00      0.83         5\n",
      "          22       1.00      1.00      1.00         5\n",
      "          23       1.00      0.80      0.89         5\n",
      "          24       0.80      0.80      0.80         5\n",
      "          25       0.50      1.00      0.67         5\n",
      "          26       1.00      1.00      1.00         5\n",
      "          27       1.00      1.00      1.00         5\n",
      "          28       1.00      0.40      0.57         5\n",
      "          29       0.83      1.00      0.91         5\n",
      "          30       0.71      1.00      0.83         5\n",
      "          31       1.00      1.00      1.00         5\n",
      "          32       1.00      0.80      0.89         5\n",
      "          33       1.00      0.80      0.89         5\n",
      "          34       1.00      1.00      1.00         5\n",
      "          35       0.00      0.00      0.00         5\n",
      "          36       1.00      0.80      0.89         5\n",
      "          37       0.57      0.80      0.67         5\n",
      "          38       1.00      1.00      1.00         5\n",
      "          39       1.00      1.00      1.00         5\n",
      "          40       1.00      0.40      0.57         5\n",
      "\n",
      "    accuracy                           0.87       200\n",
      "   macro avg       0.88      0.87      0.86       200\n",
      "weighted avg       0.88      0.87      0.86       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramez\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ramez\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ramez\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "classifier.fit(A1_train, y1_train)\n",
    "y_predicted = classifier.predict(A1_test)\n",
    "results = metrics.classification_report(y1_test, y_predicted)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for k = 3 the accuracy gained is less than the accuracy yeilded at  k = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.60      0.75         5\n",
      "           2       0.62      1.00      0.77         5\n",
      "           3       1.00      0.80      0.89         5\n",
      "           4       0.83      1.00      0.91         5\n",
      "           5       0.62      1.00      0.77         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       0.71      1.00      0.83         5\n",
      "           8       1.00      1.00      1.00         5\n",
      "           9       0.83      1.00      0.91         5\n",
      "          10       1.00      1.00      1.00         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       1.00      1.00      1.00         5\n",
      "          13       1.00      0.80      0.89         5\n",
      "          14       1.00      1.00      1.00         5\n",
      "          15       1.00      0.40      0.57         5\n",
      "          16       0.80      0.80      0.80         5\n",
      "          17       1.00      0.80      0.89         5\n",
      "          18       1.00      1.00      1.00         5\n",
      "          19       1.00      1.00      1.00         5\n",
      "          20       1.00      0.60      0.75         5\n",
      "          21       0.83      1.00      0.91         5\n",
      "          22       0.83      1.00      0.91         5\n",
      "          23       0.80      0.80      0.80         5\n",
      "          24       1.00      1.00      1.00         5\n",
      "          25       0.45      1.00      0.62         5\n",
      "          26       1.00      1.00      1.00         5\n",
      "          27       0.83      1.00      0.91         5\n",
      "          28       1.00      0.40      0.57         5\n",
      "          29       0.71      1.00      0.83         5\n",
      "          30       1.00      1.00      1.00         5\n",
      "          31       1.00      1.00      1.00         5\n",
      "          32       1.00      1.00      1.00         5\n",
      "          33       1.00      1.00      1.00         5\n",
      "          34       1.00      1.00      1.00         5\n",
      "          35       0.00      0.00      0.00         5\n",
      "          36       1.00      0.60      0.75         5\n",
      "          37       0.57      0.80      0.67         5\n",
      "          38       1.00      0.80      0.89         5\n",
      "          39       1.00      1.00      1.00         5\n",
      "          40       1.00      0.40      0.57         5\n",
      "\n",
      "    accuracy                           0.86       200\n",
      "   macro avg       0.89      0.86      0.85       200\n",
      "weighted avg       0.89      0.86      0.85       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=5, weights = \"distance\")\n",
    "classifier.fit(A1_train, y1_train)\n",
    "y_predicted = classifier.predict(A1_test)\n",
    "results = metrics.classification_report(y1_test, y_predicted)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy = 0.86 which is less than the accuracy yeilded at k=1 and k=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### k=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.60      0.75         5\n",
      "           2       0.62      1.00      0.77         5\n",
      "           3       1.00      0.80      0.89         5\n",
      "           4       0.83      1.00      0.91         5\n",
      "           5       0.40      0.80      0.53         5\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       0.83      1.00      0.91         5\n",
      "           8       1.00      1.00      1.00         5\n",
      "           9       0.80      0.80      0.80         5\n",
      "          10       1.00      0.80      0.89         5\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       1.00      0.80      0.89         5\n",
      "          13       1.00      0.80      0.89         5\n",
      "          14       1.00      1.00      1.00         5\n",
      "          15       1.00      0.40      0.57         5\n",
      "          16       0.83      1.00      0.91         5\n",
      "          17       1.00      0.60      0.75         5\n",
      "          18       1.00      1.00      1.00         5\n",
      "          19       0.71      1.00      0.83         5\n",
      "          20       1.00      0.40      0.57         5\n",
      "          21       0.83      1.00      0.91         5\n",
      "          22       0.83      1.00      0.91         5\n",
      "          23       0.80      0.80      0.80         5\n",
      "          24       1.00      1.00      1.00         5\n",
      "          25       0.38      1.00      0.56         5\n",
      "          26       1.00      0.60      0.75         5\n",
      "          27       1.00      1.00      1.00         5\n",
      "          28       1.00      0.40      0.57         5\n",
      "          29       0.62      1.00      0.77         5\n",
      "          30       1.00      1.00      1.00         5\n",
      "          31       1.00      1.00      1.00         5\n",
      "          32       1.00      0.60      0.75         5\n",
      "          33       1.00      1.00      1.00         5\n",
      "          34       1.00      1.00      1.00         5\n",
      "          35       0.00      0.00      0.00         5\n",
      "          36       1.00      0.80      0.89         5\n",
      "          37       0.57      0.80      0.67         5\n",
      "          38       0.71      1.00      0.83         5\n",
      "          39       1.00      1.00      1.00         5\n",
      "          40       1.00      0.20      0.33         5\n",
      "\n",
      "    accuracy                           0.82       200\n",
      "   macro avg       0.87      0.82      0.81       200\n",
      "weighted avg       0.87      0.82      0.81       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=7, weights='distance')\n",
    "classifier.fit(A1_train, y1_train)\n",
    "y_predicted = classifier.predict(A1_test)\n",
    "results = metrics.classification_report(y1_test, y_predicted)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy = 0.82.\n",
    "We can conclude that the more neighbors are, the less the accuracy will be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different train/test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.60      0.75         5\n",
      "           2       1.00      1.00      1.00         3\n",
      "           3       1.00      0.75      0.86         4\n",
      "           4       0.50      1.00      0.67         2\n",
      "           5       0.75      1.00      0.86         3\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      1.00      1.00         4\n",
      "           8       1.00      1.00      1.00         3\n",
      "           9       1.00      1.00      1.00         3\n",
      "          10       1.00      1.00      1.00         5\n",
      "          11       1.00      0.75      0.86         4\n",
      "          12       1.00      1.00      1.00         5\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       1.00      1.00      1.00         2\n",
      "          15       0.60      1.00      0.75         3\n",
      "          16       1.00      1.00      1.00         2\n",
      "          17       1.00      1.00      1.00         5\n",
      "          18       1.00      1.00      1.00         5\n",
      "          19       1.00      1.00      1.00         2\n",
      "          20       1.00      0.67      0.80         3\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       1.00      1.00      1.00         3\n",
      "          23       1.00      0.80      0.89         5\n",
      "          24       1.00      1.00      1.00         2\n",
      "          25       1.00      1.00      1.00         3\n",
      "          26       1.00      1.00      1.00         1\n",
      "          27       1.00      1.00      1.00         3\n",
      "          28       1.00      0.80      0.89         5\n",
      "          29       1.00      1.00      1.00         2\n",
      "          31       1.00      1.00      1.00         2\n",
      "          32       1.00      0.80      0.89         5\n",
      "          33       0.50      1.00      0.67         1\n",
      "          34       1.00      1.00      1.00         4\n",
      "          35       1.00      1.00      1.00         1\n",
      "          36       1.00      1.00      1.00         3\n",
      "          37       0.50      1.00      0.67         1\n",
      "          38       0.83      1.00      0.91         5\n",
      "          39       1.00      1.00      1.00         1\n",
      "          40       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.93       120\n",
      "   macro avg       0.94      0.95      0.93       120\n",
      "weighted avg       0.96      0.93      0.94       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#70/30\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_matrix, labels, test_size=0.3)\n",
    "Ur = get_reduced_eigenvectors(x_train, 0.95)\n",
    "A_train = pca(Ur, x_train)\n",
    "A_test = pca(Ur, x_test)\n",
    "classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "classifier.fit(A_train, y_train)\n",
    "y_predicted = classifier.predict(A_test)\n",
    "results = metrics.classification_report(y_test, y_predicted)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         3\n",
      "           3       0.67      1.00      0.80         2\n",
      "           4       1.00      0.50      0.67         2\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       1.00      1.00      1.00         3\n",
      "           9       0.33      1.00      0.50         1\n",
      "          10       1.00      0.67      0.80         3\n",
      "          11       1.00      1.00      1.00         2\n",
      "          12       1.00      1.00      1.00         2\n",
      "          13       1.00      1.00      1.00         2\n",
      "          14       1.00      1.00      1.00         2\n",
      "          15       1.00      1.00      1.00         1\n",
      "          17       1.00      1.00      1.00         3\n",
      "          18       1.00      1.00      1.00         5\n",
      "          19       1.00      1.00      1.00         1\n",
      "          20       1.00      1.00      1.00         1\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       0.67      1.00      0.80         2\n",
      "          23       1.00      0.33      0.50         3\n",
      "          24       1.00      1.00      1.00         2\n",
      "          25       1.00      1.00      1.00         1\n",
      "          26       1.00      1.00      1.00         3\n",
      "          27       1.00      1.00      1.00         1\n",
      "          28       1.00      1.00      1.00         1\n",
      "          29       1.00      1.00      1.00         3\n",
      "          30       1.00      1.00      1.00         4\n",
      "          31       1.00      1.00      1.00         2\n",
      "          32       1.00      1.00      1.00         1\n",
      "          33       1.00      1.00      1.00         2\n",
      "          34       1.00      1.00      1.00         2\n",
      "          35       1.00      1.00      1.00         2\n",
      "          36       1.00      1.00      1.00         2\n",
      "          38       0.50      1.00      0.67         1\n",
      "          39       1.00      0.67      0.80         3\n",
      "          40       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.94        80\n",
      "   macro avg       0.95      0.95      0.94        80\n",
      "weighted avg       0.97      0.94      0.94        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#80/20\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_matrix, labels, test_size=0.2)\n",
    "Ur = get_reduced_eigenvectors(x_train, 0.95)\n",
    "A_train = pca(Ur, x_train)\n",
    "A_test = pca(Ur, x_test)\n",
    "classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "classifier.fit(A_train, y_train)\n",
    "y_predicted = classifier.predict(A_test)\n",
    "results = metrics.classification_report(y_test, y_predicted)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By trying different splits for the training and test sets, the best results were yeilded by spliting the data 80% for training and 20% for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
